"optim": "adamw_torch"
"learning_rate": 1e-06
"warmup_steps": 200
"adam_beta1": 0.9
"adam_beta2": 0.98
"weight_decay": 0.1
"adam_epsilon": 1e-10
"warmup_ratio": 0.1