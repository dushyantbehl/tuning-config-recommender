"learning_rate": 1e-06
"num_train_epochs": 1
"max_steps": 10
"max_seq_length": 8192
"per_device_train_batch_size": 32
"split_batches": true
"save_strategy": "epoch"
"logging_strategy": "steps"
"logging_steps": 1
"lr_scheduler_type": "linear"
"warmup_ratio": 0.03
"gradient_accumulation_steps": 1
"gradient_checkpointing": true
"gradient_checkpointing_kwargs": '{"use_reentrant": true}'